# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: (12000, 29)
- Целевая переменная: `target` 0-1 - классы    0.676583-0.323417 - соотношение
- Признаки: что за типы (числовые(25) и категориальные-подобные(4))

## 2. Protocol

- Разбиение: train/test (доли=75%/25%, `random_state = 42`)
- Подбор: CV на train (сколько фолдов - 5, что оптимизировали - accuracy)
- Метрики: accuracy, F1, ROC-AUC (и почему эти метрики уместны именно здесь)
Accuracy — общая доля правильных ответов. F1 — гармоническое среднее точности и полноты, учитывает дисбаланс. ROC-AUC — оценивает качество ранжирования вероятностей, устойчив к умеренному дисбалансу. Все три метрики дают полную картину качества в бинарной задаче.

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier (baseline): strategy="most_frequent" — всегда предсказывает класс 0.
- LogisticRegression (baseline из S05): Pipeline(StandardScaler → LogisticRegression), обучена без подбора.
- DecisionTreeClassifier (контроль сложности: max_depth + min_samples_leaf или ccp_alpha): подбор max_depth, min_samples_leaf.
- RandomForestClassifier: подбор max_depth, min_samples_leaf, max_features.
- Один boosting (GradientBoosting): GradientBoostingClassifier, подбор n_estimators, max_depth, learning_rate.

Опционально:

- StackingClassifier (с CV-логикой) - нет.

## 4. Results

- Таблица/список финальных метрик на test по всем моделям
DecisionTree         | Acc: 0.8713 | F1: 0.7942 | AUC: 0.9054
RandomForest         | Acc: 0.9243 | F1: 0.8768 | AUC: 0.9674
GradientBoosting     | Acc: 0.9353 | F1: 0.8967 | AUC: 0.9709
- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснение
Победителем стала GradientBoostingClassifier (ROC-AUC = 0.9709)(Accuracy = 9353). Она показала наивысшее качество ранжирования и баланс между точностью и полнотой (F1=0.8967), что делает её лучшим выбором для данной задачи.

## 5. Analysis

- Устойчивость: что будет, если поменять `random_state` (хотя бы 5 прогонов для 1-2 моделей) – кратко. Метрики будут незначительно меняться.
- Ошибки: confusion matrix для лучшей модели + комментарий. Confusion matrix сохранена в figures/, показывает низкое число ошибок
- Интерпретация: permutation importance (top-10/15) + выводы. Все важные признаки — числовые, что соответствует синтетической природе данных. Категориальные признаки не вошли в топ-10, что может означать их меньшую предсказательную силу в этой генерации данных.

## 6. Conclusion

- Деревья склонны к переобучению, поэтому очень важно контролировать max_depth, min_samples_leaf

- Ансамбли превосходят деревья и линейные модели

- Честный ML-протокол (фиксированный split, CV на train, single test evaluation) обеспечил воспроизводимость и объективное сравнение.

- ROC-AUC и F1 информативнее accuracy при умеренном дисбалансе.